{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing **Torch** and **CIFAR10** dataset"
      ],
      "metadata": {
        "id": "XXX4NBMIimtp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "ppL9VHoPh_9B"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "from torchvision.datasets import CIFAR10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spliting the dataset into **train** and **test** sets"
      ],
      "metadata": {
        "id": "w8qcEHQLjOwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = CIFAR10(root = 'data', train = True, download= True) \n",
        "test_data = CIFAR10(root = 'data', train = False, download= True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH46-0N5ix_Y",
        "outputId": "86d233eb-5ea9-427b-ff94-bb088f1b8cea"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking** the dataset length"
      ],
      "metadata": {
        "id": "nIafTjxrjevA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data) # has 50000 data in train set\n",
        "len(test_data) # has 10000 data in test set\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZIKamh_jLqm",
        "outputId": "e4d0572d-997e-4eab-bfa5-9abc7597aa5a"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 50000\n",
              "    Root location: data\n",
              "    Split: Train"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the dataset **image** and **label**"
      ],
      "metadata": {
        "id": "EYwX7NQ_j1we"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im, gt = train_data[15]\n",
        "print(type(gt)) # get gt type which is int\n",
        "display(im)\n",
        "im.size # can get the size 32 X 32\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "-os9T5zfjm0Q",
        "outputId": "4bf926a3-33ae-487a-d637-3b80bd26044c"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'int'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FE99F4AB310>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt # import matplotlib\n",
        "\n",
        "plt.imshow(im) # get image\n",
        "plt.title(f'Target: {gt}') # get label \n",
        "plt.axis('off') # off x and y axises "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "5FteOk_rkMQJ",
        "outputId": "37a802ce-a5de-4eab-9d93-e6a99d8a3ce1"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 31.5, 31.5, -0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAeIUlEQVR4nO3ce4xddd3v8e9a+z6XTm/TK2V6AcHWg3jgmPMfBtSKSE+CCRZD4iUhNWJCiPoXIYCXPxAF/yBBhcCJiBeMxgOBQIjWSMB6jMGcw4NAoReklLbTzn1mX9fv/GH8Ps88Rfv9YOd00PcrMXk6z7ffrr3X2vsza5j9yVJKyQAAMLP8TB8AAGDxIBQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUMAZkWVZ6H+//vWvz/ShzvPss8/arbfeauPj4//Qnk6nY7fddptt3rzZarWabd682b72ta9Zt9s9PQcKvE3lM30A+Nf04IMPzvvz97//fXvqqadO+vq73/3u/5+HdUrPPvus3XbbbfbpT3/ali5d+rb3XHvttfbTn/7UPvvZz9rFF19se/bssZtvvtlee+01+973vnf6DhgQEQo4I6699tp5f96zZ4899dRTJ3397UgpWbPZtEaj8Q/vWgi///3v7eGHH7abb77ZvvKVr5iZ2ec+9zlbuXKl3XnnnfaFL3zBLrjggjN8lPhXxY+PsGg98MADdumll9qqVausVqvZ1q1b7Z577jlpbuPGjfaxj33MnnzySbv44out0WjYd7/7XTMzO3jwoO3YscP6+/tt1apVduONN9qTTz75lj+a+t3vfmcf+chHbGhoyPr6+uySSy6xZ555xv//t956q335y182M7NNmzb5j7gOHDhgZmajo6P24osv2uzs7N99XE8//bSZme3cuXPe13fu3GkpJfvJT34iPU/A6cSdAhate+65x7Zt22Y7duywcrlsjz76qH3+85+3oijs+uuvnzf70ksv2TXXXGO7du2y6667zs477zybmZmxSy+91A4fPmw33HCDrVmzxn74wx/a7t27T/q3fvWrX9nll19uF110kd1yyy2W57mH0tNPP23vf//77aqrrrKXX37ZfvSjH9ldd91lK1euNDOz4eFhMzO7++677bbbbrPdu3fbBz7wgb/5uFqtlpnZSXcyfX19Zmb2hz/84W0/Z8A/LAGLwPXXX5/+8+U4Ozt70tz27dvT5s2b531tZGQkmVl64okn5n39W9/6VjKz9Itf/MK/Njc3l84///xkZmn37t0ppZSKokjnnntu2r59eyqKYt6/v2nTpvShD33Iv3bHHXckM0v79+8/6dhuueWWeXv/lp/97GfJzNKDDz447+vf+c53kpml97znPX/37wMLiR8fYdH6j99JT0xM2OjoqF1yySW2b98+m5iYmDe7adMm2759+7yvPfHEE7Z+/XrbsWOHf61er9t11103b+6Pf/yj7d271z75yU/a8ePHbXR01EZHR21mZsYuu+wy+81vfmNFUZzyeG+99VZLKf3duwQzs49+9KM2MjJiX/rSl+znP/+5HTx40B5++GG76aabrFwu29zc3Cn/LWCh8OMjLFrPPPOM3XLLLfbb3/72pJ/TT0xM2NDQkP9506ZNJ/39gwcP2pYtWyzLsnlfP+ecc+b9ee/evWZm9qlPfepvHsvExIQtW7ZMfgxvpV6v22OPPWZXX321ffzjHzczs1qtZt/4xjfs61//ug0MDJyWfwd4OwgFLEqvvvqqXXbZZXb++efbnXfeaRs2bLBqtWqPP/643XXXXSd95/6P/KbRX3fdcccdduGFF77lzOl+o962bZs9//zz9sILL9jY2Jht3brVGo2G3XjjjXbJJZec1n8LUBAKWJQeffRRa7Va9sgjj9jZZ5/tX3+r/0j8t4yMjNgLL7xgKaV5dwuvvPLKvLktW7aYmdmSJUvsgx/84N/d+Z/vOv4RWZbZtm3b/M+PP/64FUVxymMAFhL/TQGLUqlUMrO/fObgryYmJuyBBx4I79i+fbsdOnTIHnnkEf9as9m0e++9d97cRRddZFu2bLFvfvObNj09fdKeY8eO+f/d399vZvaWn2iO/krqW5mbm7Obb77Z1q5da9dcc43894HThTsFLEof/vCHrVqt2pVXXmm7du2y6elpu/fee23VqlV2+PDh0I5du3bZ3Xffbddcc43dcMMNtnbtWnvooYesXq+b2b9/15/nud133312+eWX27Zt2+wzn/mMrV+/3g4dOmS7d++2JUuW2KOPPmpmfwkQM7ObbrrJdu7caZVKxa688krr7+8P/0qqmdnVV19t69ats61bt9rk5KTdf//9tm/fPnvsscdscHDwbT5rwGlwhn/7CUgpvfWvpD7yyCPpggsuSPV6PW3cuDHdfvvt6f777z/pV0JHRkbSFVdc8ZZ79+3bl6644orUaDTS8PBw+uIXv+i/Erpnz555s88991y66qqr0ooVK1KtVksjIyPp6quvTr/85S/nzX31q19N69evT3mezzuW6K+kppTS7bffns4///xUr9fTsmXL0o4dO9Jzzz13yr8HLLQspf9wfw78C/j2t79tN954o73++uu2fv36M304wKJCKOCf2tzc3LzfTGo2m/a+973Per2evfzyy2fwyIDFif+mgH9qV111lZ199tl24YUX2sTEhP3gBz+wF1980R566KEzfWjAokQo4J/a9u3b7b777rOHHnrIer2ebd261X784x/bJz7xiTN9aMCixI+PAACOzykAAByhAABw4f+mcN1P3hRXn7pV8q+ypFUHZMIPvFIeP46/iM+Xiqq2WahI6GY9abf4FJr2tCzcTxgX9meX4pOiNlgsmp+8Lp7v7ZJwRpPwWns7tNNTErcLF4t4nSSLv/azXLto/+fOdaecWTxXEwDgjCMUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAALhw91EpF3teivh8pvb8CFlWWEXanQsx2cu1486L+Hy/+HQrnTNmZt1S/IH2xF6YborvzlNX2p1Jj1PtJlK7kpT9arFS3OJqv1f6jBa4+Up6yhewh2khO7W0BxnCnQIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAAF665KJe1qoOkfGpc/Kh2kcWPpZK03bXubHx3rlU0rBiMzy+vTEi7j7x5TJrf+2b8WOorR6TdtcFV8eFcqyFJxQLWEbxDJfEazxawcqMQ6iJSpp3LhTxuldYsotZ5xN/fMqWXJ4g7BQCAIxQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAuHD3UV4Oj/5FL95TUk4taXXenQ7PljonpN3Lsvh8vaX1E523Zn18d7kj7Z7dd0Carx4bC882p45Iu/NlwuNcdY60u9q/NDxbZFVpdyFW1GRCz4/ef6Os1jqBUqYci7Y7T8r3mWKPldiRJtHKjKSzmcTdynOe030EAFhIhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMCFuyv6yk1pcX8xE57tTu2Xdtc78YqGejEp7V6/Znl4tjXTlXYvbcSrQjLx4+vVRkOaX7suXgGRcq0uYmLmYHh2av9haXdzYF14trHmXdLu6uCwNJ+E76kKtdFBqDrIUk/aXeTx6zaTaiu0+ZSp35OKdRHCuNgUssCEc5+VTvu/zp0CAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAABcuIznvOob0uK+3mh4dro6Ie3Oa/HZ1KlIu2tloZ+o3i/tHhhcEp7tdOek3dVaXZrP8lZ4tlbXdtfq8edwqKV1ao3Pvh6endl/VNrdGzpLmu9buTk8WxlcKe3uZvGLvNzTuo+S0JeTiaVAynQv1wqhklh9pJQfLaruI+Fg1I60CO4UAACOUAAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAALhwH8Ha0glpcbfeCc+Wsj5pd1a0w7NzmVZzkWfxnMwyrV6gJHwkPZXjVQRmZuVKvFrCzCzP4s+hKgllB/V6Q9o9LFScDLTj16CZ2dTMQWl+fDpeo1FdsUHa3T88Ep6tNIak3d08fq0o59LMLEvx6oqKuFuvuYjvX8iaiyQfODUXAIBFglAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4MIlKH1iR81UN97fUS3ifSlmZp1uvHOoMK1DqOh0w7NJPG6lAaVSETubxA6UJB3NwnW3FEk77kLokalWq9LuoUwrwBkUzv/Eif3S7vETh8Kz/as3SrsH120Jz2b1JdJuofrIrNCuq0w8Pwq5VknaLW4XxrP89D8n3CkAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcOGaixXDq6TFxfE3w7OTU5PS7l5X+Cy9UItgZlYRqhFSHq/EMFPKH8zKJa3molzS6jyS0kcg1gvkUoOGdn6U4y7EGpITr2hVFGWhyqV/2XJp98BAvF5i8ug+afeJ8aPh2f5VI9Lu/rXx+azRL+22Xrzexsyka6tQKzSE8Uzt0JBqLrTXfQR3CgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcOHuoyzTemRSipeDtLpap0mv0wnPlsRKk1qjL34cc7PSbiWB5b4UUb6A/4DyOAul6MWkWhj5Oay1Wtp8O/6amGhp10p9zfrw7NCa1dLubjPeNTZz6E/S7umpeK/S8nUbpd19y9dK81YTupV62vubciXKLzXlL+Sn//t67hQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAODC3UdF0vqJ2kI/UVFovSPVSjU8m8RunUo1vjtvNaXdGq20Kc+0+UzpbhGfQ6kXRtytHbcmT9p1mJfj31MNLBmQdre63fBsr6e9NmuVSni2LF5XzZl499H4S8ek3VMrNkjzy89+V3h2ydByabfSOdRLC9fvtQDVR9wpAAD+HaEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAARygAAByhAABw4ZoLEz+qrZQMZOrHwIVP3ufi58BLwrzYACDVLnSFmgMzs06nrR2MUOmQiRUnJrVFiNeVUkUhrs7EupVmuxWerTaWSbtbkzPh2ckjR6Tdq4fXhGezkrRaqqApZfG3HzOzzuSb0vyJP42GZ6eGz5J2r9owEp7tW7pU2l0Ib3Dqe2cEdwoAAEcoAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHDh8hG1Q6hSqQizWgdK0RN6e8SCIvVxSrtL8SKZ8ckxaffhN96Q5ote/PzIvVdCP5Hc3KLsFo87E4+mELqSCqWzycxSL959NT52XNrdasePpTEwKO1u9NXCs9VafNbMrJJr7xNJOD/dI69Luw9PngjPLl2zTtq9fH28h6k2uFTaHcGdAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAAAX/tx4u9OWFittEZWa9vH1Tks5FrFeQJxXZMLuvKw9J/39dWl+thOvUUjWk3anTHgO5QYNoeZCPJWdqla70JmLX4fZTEvaXSrF61lKXe2BTk5NhGenpyel3dVKvMpl9Tqt/qHW6JfmhTYca9T6pN3dTvx8Thx8VdpdEt4nNrx3mbQ7gjsFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAC4cMHO3FxTWtwRupKq1Yq0u92K944UQleOKutqnUB5pxOeLefxDhkzs3qlKs1nFu8+KpLYfVSIhUbS7vj5LIp4f5CZWWXlcu1Y+uJ9U61MO5ZSLd7DtKG+UtrdjJ96m52dkXbPzcbfJ7rt+OvBzKyUa+9BrW78gZbFrjHldFaE172ZWb0Xf5z9Je21aXbq9xXuFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAC48Ge71bqIbi/+8eua+BHzUileAZHnWu4p87laodGai+/OtJqLXk87lmRKFYVW0aBUAKS0cJUYYrOETTZnpfl2L15fMLRshbRbqQrJ2vFKGTOzRjleK5P39Um7+/oGwrNqtUSvJ/RzmFkunP9eJ/7aNDMrhKqdklhzURVqZfrK2vtEBHcKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAARygAAByhAABw4fKRXCkSMbNcKJ5R+28yYbfafaTodeL9J2ZmWTfeUdPL4v00ZmYzc01pvhC6qcpqiZBAPfdKZ1NK2nFXK1Vp/tiR0fDs5MSMtLtRq4dnl4ivzcLiPVntSkPa3bR4F09J7D6SyozMrFyLn89cvA67U/HzWS1r70HTY0fDs8X4EWm3Da8+5Qh3CgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcOHykXJZ6+IpC70m3Va8E8jMrBB6Sspi95HSlVQRulXMzFIp3t2i9DuZmS1fsVyaH5uO96vIzUfCscu7hYqalOIdP2Zm1WpNm6/H+4lmW1pPVr0Uvw6Ljvj6EXqvms2utHusJcyX4z1JZmblitaVVK7GX5/l5cPS7k6nIxyH1h/1573/Fh9uat1H/+PcXaec4U4BAOAIBQCAIxQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgAt/brxU0j5i3u0KFQOZmE1CXYQJdQFmZnke313p65N2Nyvxj7unrlZdUK9p56ckPC9aGYFZoXRRyD0XC6fe0GouztqwLjzb6cSrJczMMuH7Nbnmooi/Nuttbfcq4bXcTdrJz+TKmviV2y20Oo+2UqHSildimJmldrwS5cXnn5d2R3CnAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAAFy7M6XbFbpBWvDOlIXbO5J14p0mWif0qwnxb6JAxM5vpxJ/DZNru6dlZaT4loZ9ImTWT+ozU82PqvKDb0Tpqms258GwqtOPuCd1h3Z7Wq6Q8h+VqVVpdKwt9Q+Jhz7W196BON37d9jLtGu9l8cfZUnrgzKyYiz/O1UtXSrsjuFMAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4MI1F61mS1rcEz56n+daNpVK8Y+Yq7uVCoDZlvac1Nvx6g/1sCempqT5IgkfvZerJZTKALGGZME2mxVinYcy3hMrUZRjKcQWEuU1kTLtQkzC95mp0GorCrFqpyc85YV6foSOjqb43jl15Eh4dvSA9rqP4E4BAOAIBQCAIxQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAAAu3H3U398nLZ6cmQnPqv1EmdDFo+6WOlB6WulMKYt3NlUr4VNjZmarh1dJ89MzR6V5hXJ+pAIhM0sL2AlUq1Wl+Vzo4Gq1OtLuXle4DtvxHh4zs57QTdUS+rrMzJR6om5HPO52U5pvN2fDs7PTE9LuibHx8OzxY8ek3dOT8WMZGtLelyO4UwAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgwl0K7Y7w+XUza7Vb4dlOR6sASCleAVCratUFU5OTyoFIu0t5vP6hWolXKJiZVYXKBTOzTKg6UKolzMyS0C9RdLWqg6KIX4dFEuo2zKwpVlHMzs7Fh8XKDeVY2h2tiqLXiz+HXfG4+xqV8Gxe0p7vVm9Kmv/z/pfCsxMnxqTdvbl45cb0lPCeYma5UHFT5APS7tC/f9o3AgDesQgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAC5csjEndH2YmdWrtfBsuy12HxXx7qPmnNBPY2aFcCzdnnbc3W58fnpae76nJsal+ebsdHg262odQr1O/PzIvT0p3pWUktYH1ZzTjmV2diY82+5oHU+T0/HzMzOl9fZMjp8Iz57z7vdIu//7f/0v4dnXD7ws7X7p6KvSfHs6/jj7+7SOtHHh3HfE/qj+oeHwbGP1OdryAO4UAACOUAAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAALhwzUWvrVUAWCs+Xylp2TQpVFekbrxywcxscMXK8GxTrP5YuWx5eHbfgQPS7kOHDkvzx4+OhmdrA11pd2bxWoxWodU/dLrxY+nMatfs5PF4LYKZ2bHRI+HZo6Pa7hPjU+HZ5qS2u9WJX7f1wQFpd5YuDM+uWxl/PZiZjS8fkuaH/tv7wrNjM1odzv8pDoZns+ERafeac94bnh1YsU7aHcGdAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAXLj7aO8LL0iL261WeLYoi91H0xPh2Vzo4TEzmzhxPH4cE5PS7r5KfDar1qTdpVJJmh8fPRqebXSStLvZjJ/7I8fix2Fmdnwi3gk0I/QHmZlNiscyNS2c/0pD2r18eHV4dq7XkXZXhNfb+Ni4tPvY0XgH17tG4o/RzOy9779Imt93KP5afuOFeJeRmdnyjVvDs7Wl66Xd1Ua84ynPtdd9aOdp3wgAeMciFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAC4cPdRb64pLZ6Zm4kfxECftLtei/cCtWZnpd2jx46EZ8fHTki7n5uLd7EsX3uWtHtmRuv56XXa4dnXDuyXdh8fjT/Og/u13eXBeC+MFVpn0/RUvFPLzKxXFOHZ/iHtGm/0D4ZnZ/q0XqVmK/5abra60u6JsfjufSl+nZiZvfhnrZvqz2PxDq52vkLa3bcqfh1mJe3cK31GeX76v6/nTgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAC9dcLF23QVo8fjBeX7B0SPuI+fp1a+LHceKYtDv1OuHZg0V81szs1Rf/LTy7UqlzMLNG6knzyeIVEJ3WnLR7sL8/PFup1qXdZ581Ep4VWy7slelpab43F68WyUvawcw143URWVaRdmdFfLd4WdkfX4nXxJQqY9LubhavtzEzKzVWhWcbFe06NKGKwpIwa2Z5ptRcaOc+tPO0bwQAvGMRCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAABcuPuo1Ij32ZiZ1QeWxIdzLZsajUZ4ttM/KO3+X7/4eXx3U+sEmpmYDc8eePU1aXdH6EsxMxsbnwjPtttax1OviJ/PvkHhOjGzTrsdPw7LpN21Wp80356LdwhZoZ0fs3inTVaqSpu78Ze9FRXtOZnoxo97SZ927mv1AWk+E3qBipL6/bEwn2m7S8qx5IW0O7TytG8EALxjEQoAAEcoAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAAAX/rx70hoDbOXwyvBsvaZVABQW/2h3L0mr7f8+/2J4tlLWjnugL14Z8Ks9f5B2r1l/ljSflWvh2cGlWlVIs9UNz5Ynp6XdkzPx+VIpXnNgZlapavNZHn9RtAutjqCSx6+tylD8tWZmtuGszeHZFSPnSbuXLl8bnq2I1Sx5WTs/lgt1HuK3x8rbSi7WXFgp/ryoVS4R3CkAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMCFy0Fa3Y60eGjpUHi2UatKu7tCj0wu9hN99IorwrOTY2PS7tcOvhaeXb1W6zIa2XyONP+nva+GZ2fm2tLuoh1vhukl7fx0e8q517pyNmzcJM1Pz8V7mFKtLu3uW7EqPLt0RbxvyMxsxcrV4dlyLd7XZWZWKsVfyyWx+ygTX8uWx7/n7YnlbknoXzNp1iyleHdYRejfiuJOAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4AgFAIAL11yUhI+Mm5nNzM6GZ6cmpqTdPaHq4MSxN6TdzVb8uMviR8zXrI3XEZy9aYu0+9n//Xtp/vDR4+HZvv4l0u5eL15z0eloFQDlaiN+HIVWi3BiKl4vYGY2vGFrfHbkXGl337J4zUm13i/tLpfDL3u5RqEi7C5M290ttPOTUvzaUis3yuX4++GSQe38jKxeGp7dtHaFtDuCOwUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAALgspRQvqgEA/FPjTgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOD+HwcU0ct9aga4AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appyling **Augmentations**"
      ],
      "metadata": {
        "id": "3DB5EqzBmeLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms as T\n",
        "\n",
        "def applying_T(root):\n",
        "  \n",
        "  \"\"\"This function get saved dataset and apply some transformations to my data\"\"\"\n",
        "  \n",
        "  # applying a few transformations to TRAIN dataset\n",
        "\n",
        "  train_data_T = T.Compose([\n",
        "      T.RandomVerticalFlip(), # Flip Vertically\n",
        "      T.ToTensor(), # change to Tensor values # (H, W, img_chan.)\n",
        "      T.RandomHorizontalFlip(), # Flip Horizontally\n",
        "      T.Normalize(mean = 0.5, std = 0.5)\n",
        "  ])\n",
        "\n",
        "  # applying a few transformations to TEST dataset\n",
        "\n",
        "  test_data_T = T.Compose([\n",
        "      T.RandomHorizontalFlip(), # Flip Horizontally\n",
        "      T.ToTensor(), # change to Tensor values # (H, W, img_chan.)\n",
        "      T.Normalize(mean = 0.5, std = 0.5)\n",
        "  ])\n",
        "\n",
        "  train_data = CIFAR10(root = root, train = True, transform = train_data_T, download = True)\n",
        "  test_data = CIFAR10(root = root, train = False, transform = test_data_T, download = True)\n",
        "\n",
        "  return train_data, test_data\n",
        "\n",
        "after_T, test_data = applying_T(\"data\") # train dataset is renamed\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "185-MrmjlPFg",
        "outputId": "0853cbfb-dffa-4d3f-8c4c-50f73dc72216"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im, gt = after_T [0] # getting the 0 index of my train set element and change it to tensor\n",
        "torch.unique(im) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXyi_ixrw5Ck",
        "outputId": "d392feb0-6aa3-42a6-a1a9-7966eb0c705e"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.0000, -0.9686, -0.9608, -0.9451, -0.9373, -0.9294, -0.9216, -0.9137,\n",
              "        -0.9059, -0.8980, -0.8902, -0.8824, -0.8745, -0.8667, -0.8588, -0.8510,\n",
              "        -0.8431, -0.8353, -0.8275, -0.8196, -0.8118, -0.8039, -0.7961, -0.7882,\n",
              "        -0.7804, -0.7725, -0.7647, -0.7569, -0.7490, -0.7412, -0.7333, -0.7255,\n",
              "        -0.7176, -0.7098, -0.7020, -0.6941, -0.6863, -0.6784, -0.6706, -0.6627,\n",
              "        -0.6549, -0.6471, -0.6392, -0.6314, -0.6235, -0.6157, -0.6078, -0.6000,\n",
              "        -0.5922, -0.5843, -0.5765, -0.5686, -0.5608, -0.5529, -0.5451, -0.5373,\n",
              "        -0.5294, -0.5216, -0.5137, -0.5059, -0.4980, -0.4902, -0.4824, -0.4745,\n",
              "        -0.4667, -0.4588, -0.4510, -0.4431, -0.4353, -0.4275, -0.4196, -0.4118,\n",
              "        -0.4039, -0.3961, -0.3882, -0.3804, -0.3725, -0.3647, -0.3569, -0.3490,\n",
              "        -0.3412, -0.3333, -0.3255, -0.3176, -0.3098, -0.3020, -0.2941, -0.2863,\n",
              "        -0.2784, -0.2706, -0.2627, -0.2549, -0.2471, -0.2392, -0.2314, -0.2235,\n",
              "        -0.2157, -0.2078, -0.2000, -0.1922, -0.1843, -0.1765, -0.1686, -0.1608,\n",
              "        -0.1529, -0.1451, -0.1373, -0.1294, -0.1216, -0.1137, -0.1059, -0.0980,\n",
              "        -0.0902, -0.0824, -0.0745, -0.0667, -0.0588, -0.0510, -0.0431, -0.0353,\n",
              "        -0.0275, -0.0196, -0.0118, -0.0039,  0.0039,  0.0118,  0.0196,  0.0275,\n",
              "         0.0353,  0.0431,  0.0510,  0.0588,  0.0667,  0.0745,  0.0824,  0.0902,\n",
              "         0.0980,  0.1059,  0.1137,  0.1216,  0.1294,  0.1373,  0.1451,  0.1529,\n",
              "         0.1608,  0.1686,  0.1765,  0.1843,  0.1922,  0.2000,  0.2078,  0.2157,\n",
              "         0.2235,  0.2314,  0.2392,  0.2471,  0.2549,  0.2627,  0.2706,  0.2784,\n",
              "         0.2863,  0.2941,  0.3020,  0.3098,  0.3176,  0.3255,  0.3333,  0.3412,\n",
              "         0.3490,  0.3569,  0.3647,  0.3725,  0.3804,  0.3882,  0.3961,  0.4039,\n",
              "         0.4118,  0.4196,  0.4275,  0.4353,  0.4431,  0.4510,  0.4588,  0.4667,\n",
              "         0.4745,  0.4824,  0.4902,  0.4980,  0.5059,  0.5137,  0.5216,  0.5294,\n",
              "         0.5373,  0.5451,  0.5529,  0.5608,  0.5686,  0.5765,  0.5843,  0.5922,\n",
              "         0.6000,  0.6078,  0.6157,  0.6235,  0.6314,  0.6392,  0.6471,  0.6549,\n",
              "         0.6627,  0.6706,  0.6784,  0.6863,  0.6941,  0.7020,  0.7098,  0.7176,\n",
              "         0.7255,  0.7333,  0.7412,  0.7490,  0.7569,  0.7647,  0.7725,  0.7804,\n",
              "         0.7882,  0.7961,  0.8039,  0.8118,  0.8196,  0.8275,  0.8353,  0.8431,\n",
              "         0.8510,  0.8588,  0.8667,  0.8745,  0.8824,  0.8902,  0.8980,  0.9059,\n",
              "         0.9137,  0.9216,  0.9373,  0.9451,  0.9608,  0.9765,  0.9843,  1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spliting **CIFAR10** dataset into **Train, Validation** and **Test** sets."
      ],
      "metadata": {
        "id": "jSozBtR53xNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split, DataLoader\n"
      ],
      "metadata": {
        "id": "EnY_6F7spgb2"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_length = int(len(after_T) * 0.85)\n",
        "train_ds, validation_ds = random_split(after_T,[train_length, len(after_T) - train_length])\n",
        "print(f\"Train has {len(train_ds)} data.\") \n",
        "print(f\"Validation {len(validation_ds)} data.\")\n",
        "print(f\"Test set {len(test_data)} data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzxsFfnQ4BMf",
        "outputId": "f1117cdd-02c3-4868-d0c3-c1bc1d4f04f0"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train has 42500 data.\n",
            "Validation 7500 data.\n",
            "Test set 10000 data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset and DataLoader**"
      ],
      "metadata": {
        "id": "phkNniNiuP1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32; # batch size is 32 which is datasets / 32 \n",
        "\n",
        "# define dl(DataLoader) of train and validation datasets\n",
        "\n",
        "train_dl = DataLoader(dataset = train_ds, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4, drop_last = False)\n",
        "validation_dl = DataLoader(dataset = validation_ds, batch_size = BATCH_SIZE, shuffle = False, num_workers = 4)\n",
        "\n",
        "# define dl(DataLoader) of test dataset\n",
        "\n",
        "test_dl = DataLoader(dataset = test_data, batch_size = BATCH_SIZE, shuffle = False, num_workers = 4)"
      ],
      "metadata": {
        "id": "Yr5-dvv92Mk3"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train : {len(train_dl)} \\nValidation : {len(validation_dl)} \\nTest : {len(test_dl)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDoGcNRv5ta4",
        "outputId": "84550661-39b0-4d97-e5b7-6395ddb0adb3"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train : 1329 \n",
            "Validation : 235 \n",
            "Test : 313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_dl))\n",
        "print(batch[0].shape)\n",
        "print(batch[1].shape) #  torch.Size([32 (batch size), 3(RGB), 32, 32(pic. size)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOgAyB8h5xch",
        "outputId": "4785da01-ec42-4d88-bb3f-f3e173880489"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 32, 32])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a **Model**\n",
        "\n",
        "In model, I want to use **ReLU** (gets all positive values) and **Softmax**(sum of tensor values are equal to 1)."
      ],
      "metadata": {
        "id": "Nudqcqb_8lOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class VGG16_model(nn.Module):\n",
        "  def __init__(self, num_class = 10):\n",
        "    super(VGG16_model, self).__init__()\n",
        "\n",
        "    self.features = nn.Sequential(\n",
        "        \n",
        "        # Block 1 : VGG 16 model architecture \n",
        "\n",
        "        nn.Conv2d(3, 64, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Conv2d(64, 64, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "\n",
        "        # Block 2 : VGG 16 model architecture \n",
        "        \n",
        "        nn.Conv2d(64, 128, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Conv2d(128, 128, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "\n",
        "        # Block 3 : VGG 16 model architecture \n",
        "        \n",
        "        nn.Conv2d(128, 256, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Conv2d(256, 256, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Conv2d(256, 256, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "           # Block 4 : VGG 16 model architecture \n",
        "\n",
        "        nn.Conv2d(256, 512, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "\n",
        "        # Block 5 : VGG 16 model architecture \n",
        "\n",
        "        nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "    )\n",
        "    \n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(512*7*7, 4096),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(4096, 4096),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(4096, num_class),\n",
        "   )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "my_model = VGG16_model() # num_class = numbers of labels\n",
        "\n"
      ],
      "metadata": {
        "id": "Di-CJVMr6z2c"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agnostic code** : to check device CPU and GPU"
      ],
      "metadata": {
        "id": "_d6yF-NUHIvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'if torch.cuda.is_available() else 'cpu'\n",
        "my_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz9UpqzxDrOb",
        "outputId": "41113e3f-7ea5-41c1-f720-b01dc604acc8"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG16_model(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): Dropout(p=0.5, inplace=False)\n",
              "    (5): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Epoch / Loss / Optimizer**"
      ],
      "metadata": {
        "id": "pXC3URVEKUq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.003 # defining my learning rate \n",
        "loss_function = torch.nn.CrossEntropyLoss() # use CrossEntropyLoss minimazing my loss bcz low loss , better model\n",
        "optimizer = torch.optim.Adam(params = my_model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "OQ-p4i4uKFC7"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train Loop**"
      ],
      "metadata": {
        "id": "4pzXBgpVMAqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm # like bar graph ->\n",
        "import os\n",
        "\n",
        "peak_acc = 0 # this ll be the best accurency value\n",
        "epochs = 11\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  epoch_loss, epoch_acc, total = 0, 0, 0\n",
        "\n",
        "  for indx, batch in tqdm(enumerate(train_dl)):\n",
        "\n",
        "    i, gts = batch\n",
        "    i, gts = i.to(device), gts.to(device)\n",
        "\n",
        "    preds = my_model(i)\n",
        "    loss = loss_function(preds,gts) # print my loss value\n",
        "\n",
        "    total += i.shape[0] # save batch size to total\n",
        "    pred_val, pred_class = torch.max(preds.data, dim = 1)\n",
        "\n",
        "    epoch_acc += (pred_class == gts).sum().item() # calculate how many gts is equal to bt : 32 -> 25 , etc.\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f\"Epoch {epoch + 1} train is finished.\")\n",
        "  print(f\"Epoch {epoch + 1} train loss : -> {epoch_loss / len(train_dl)}.\")\n",
        "  print(f\"Epoch {epoch + 1} train accurancy :  -> {epoch_acc / total}.\")\n",
        "\n",
        "  my_model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    val_epoch_loss, val_epoch_acc, val_total = 0, 0, 0\n",
        "        \n",
        "    for idx, batch in enumerate(validation_dl):\n",
        "            i, gts = batch\n",
        "            i, gts = i.to(device), gts.to(device)\n",
        "            val_total += i.shape[0]\n",
        "            \n",
        "            preds = my_model(i) \n",
        "            loss = loss_function(preds, gts)\n",
        "            _, pred_cls = torch.max(preds.data, dim = 1)\n",
        "            val_epoch_loss += loss.item()\n",
        "            val_epoch_acc += (pred_cls == gts).sum().item()\n",
        "            \n",
        "    val_acc = val_epoch_acc / val_total\n",
        "        \n",
        "    print(f\"Epoch {epoch + 1} validation is finished.\")\n",
        "    print(f\"Epoch {epoch + 1} validation loss -> {val_epoch_loss / len(validation_dl)}.\")\n",
        "    print(f\"Epoch {epoch + 1} validation acc -> {val_acc}.\") \n",
        "\n",
        "    if val_acc > peak_acc:\n",
        "            os.makedirs(\"saved_models\", exist_ok = True)\n",
        "            torch.save(my_model.state_dict(), f\"saved_models/mnist_best_model.pth\") \n",
        "            best_acc = val_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9ZxPBWTL0Ig",
        "outputId": "8538251c-aa9f-44ef-8d7a-a667461f31ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1329it [01:31, 14.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train is finished.\n",
            "Epoch 1 train loss : -> 2.6532995568082423.\n",
            "Epoch 1 train accurancy :  -> 0.0995529411764706.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 validation is finished.\n",
            "Epoch 1 validation loss -> 2.3114484868151077.\n",
            "Epoch 1 validation acc -> 0.09773333333333334.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1329it [01:31, 14.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train is finished.\n",
            "Epoch 2 train loss : -> 2.310521266799479.\n",
            "Epoch 2 train accurancy :  -> 0.10014117647058823.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 validation is finished.\n",
            "Epoch 2 validation loss -> 2.306317999007854.\n",
            "Epoch 2 validation acc -> 0.0996.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1329it [01:31, 14.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train is finished.\n",
            "Epoch 3 train loss : -> 2.307845537423908.\n",
            "Epoch 3 train accurancy :  -> 0.1008.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 validation is finished.\n",
            "Epoch 3 validation loss -> 2.308439295342628.\n",
            "Epoch 3 validation acc -> 0.09773333333333334.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1329it [01:31, 14.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train is finished.\n",
            "Epoch 4 train loss : -> 2.3067332847931046.\n",
            "Epoch 4 train accurancy :  -> 0.09934117647058824.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 validation is finished.\n",
            "Epoch 4 validation loss -> 2.3033050942928233.\n",
            "Epoch 4 validation acc -> 0.09853333333333333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1329it [01:31, 14.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train is finished.\n",
            "Epoch 5 train loss : -> 2.307024438368637.\n",
            "Epoch 5 train accurancy :  -> 0.0984235294117647.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 validation is finished.\n",
            "Epoch 5 validation loss -> 2.309268122530998.\n",
            "Epoch 5 validation acc -> 0.09946666666666666.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1329it [01:31, 14.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 train is finished.\n",
            "Epoch 6 train loss : -> 2.3063067930636323.\n",
            "Epoch 6 train accurancy :  -> 0.10134117647058824.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 validation is finished.\n",
            "Epoch 6 validation loss -> 2.3073797479588936.\n",
            "Epoch 6 validation acc -> 0.09853333333333333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1329it [01:31, 14.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 train is finished.\n",
            "Epoch 7 train loss : -> 2.3070433625966826.\n",
            "Epoch 7 train accurancy :  -> 0.10098823529411764.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 validation is finished.\n",
            "Epoch 7 validation loss -> 2.3051148353738986.\n",
            "Epoch 7 validation acc -> 0.09773333333333334.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1096it [01:15, 14.36it/s]"
          ]
        }
      ]
    }
  ]
}